<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="1 概要交叉熵损失是监督学习中应用最广泛的损失函数，度量两个分布（标签分布和经验回归分布）之间的KL散度，但是也存在对于有噪声的标签缺乏鲁棒性、可能存在差裕度（允许有余地的余度）导致泛化性能下降的问题。而大多数替代方案还不能很好地用于像ImageNet这样的大规模数据集。 许多对正则交叉熵的改进实际上是通过对loss定义的放宽进行的，特别是参考分布是轴对称的。这写改进通常具有不同的动机：比如标签平">
<meta property="og:type" content="article">
<meta property="og:title" content="Supervised Contrastive Learning：有监督对比学习">
<meta property="og:url" content="http://example.com/2021/01/19/Supervised%20Contrastive%20Learning%EF%BC%9A%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="缓缓行舟">
<meta property="og:description" content="1 概要交叉熵损失是监督学习中应用最广泛的损失函数，度量两个分布（标签分布和经验回归分布）之间的KL散度，但是也存在对于有噪声的标签缺乏鲁棒性、可能存在差裕度（允许有余地的余度）导致泛化性能下降的问题。而大多数替代方案还不能很好地用于像ImageNet这样的大规模数据集。 许多对正则交叉熵的改进实际上是通过对loss定义的放宽进行的，特别是参考分布是轴对称的。这写改进通常具有不同的动机：比如标签平">
<meta property="og:locale">
<meta property="og:image" content="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.1.png">
<meta property="og:image" content="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.2.png">
<meta property="og:image" content="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.3.png">
<meta property="og:image" content="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.4.png">
<meta property="og:image" content="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.8.png">
<meta property="og:image" content="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.5.png">
<meta property="og:image" content="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.7.png">
<meta property="article:published_time" content="2021-01-19T06:56:15.028Z">
<meta property="article:modified_time" content="2021-01-19T06:59:27.102Z">
<meta property="article:author" content="微澜">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://example.com/2021/01/19/Supervised Contrastive Learning：有监督对比学习/"/>





  <title>Supervised Contrastive Learning：有监督对比学习 | 缓缓行舟</title>
  








<meta name="generator" content="Hexo 5.3.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">缓缓行舟</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">给行船途中的所感所获一个容身之处</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/01/19/Supervised%20Contrastive%20Learning%EF%BC%9A%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="缓缓行舟">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Supervised Contrastive Learning：有监督对比学习</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-19T14:56:15+08:00">
                2021-01-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="1-概要"><a href="#1-概要" class="headerlink" title="1 概要"></a>1 概要</h2><p>交叉熵损失是监督学习中应用最广泛的损失函数，度量两个分布（标签分布和经验回归分布）之间的KL散度，但是也存在对于有噪声的标签缺乏鲁棒性、可能存在差裕度（允许有余地的余度）导致泛化性能下降的问题。而大多数替代方案还不能很好地用于像ImageNet这样的大规模数据集。</p>
<p>许多对正则交叉熵的改进实际上是通过对loss定义的放宽进行的，特别是参考分布是轴对称的。这写改进通常具有不同的动机：比如标签平滑（Label smoothing）通过偏离轴来模糊区分正确和不正确的标签，从而在许多应用中提供了很小但是很重要的提升；在自蒸馏中，利用前几轮的“软”标签作为参考类分布进行多轮交叉熵训练；混合和相关数据增强策略通常通过线性插值创建明确的、新的训练示例，然后将相同的线性插值应用于目标标签分布，类似于软化原始交叉熵loss。用这些修改方法训练的模型显示了改进的泛化、鲁棒性和校准。</p>
<p>本文提出了一个新的loss，受对比loss与度量学习启发，完全去除参考分布，而只是将来自相同类的规范化嵌入强行加在一起，使得其比来自不同类的嵌入更加紧密。</p>
<p>具体来说，在对比学习中，核心思想是拉近某一个锚点与其正样本之间的距离，拉远锚点与该锚点其他负样本之间的距离，通常来说，一个锚点只有一个正样本，其他全视为负样本。而本文的方法认为每个锚点有许多的正样本，而不是许多负样本，并且通过标签显示样本之间的正负关联。比如下面的图，右侧是典型的对比学习方法，通常将一张原图通过数据增强得到两个子样本，这一对子样本之间构成一对正对，而与其他数据的子样本构成负对；而本文的有监督对比学习中，每个子样本可能都有很多的正对和负对。</p>
<img src="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.1.png" alt="正负对示例" style="zoom: 67%;" />

<p>本文构造的loss在ResNet50和ResNet200上都取得了不错的Top-1效果，在自动增强的ResNet50上取得78。8%的Top-1精度，比同样数据增强下的交叉熵loss提升了1.6%，不仅如此，还更鲁棒。</p>
<p>具体的Contribution如下：</p>
<ol>
<li>我们提出了一个新的扩展对比损失函数，允许每个锚点有多个正对。因此，我们将对比学习适应于完全监督的设置。</li>
<li>我们表明，与交叉熵相比，这种损失使我们能够了解最先进的表示方式，从而显著提高了Top-1的准确性和鲁棒性。</li>
<li>我们的损失对超参数范围的敏感性不如交叉熵。这是一个重要的实际考虑。我们相信，这是由于我们的损失使用更自然的公式，使从同一类样本的代表被拉得更近，而不是像交叉熵一样强迫他们被拉向一个特定的目标。</li>
<li>我们分析地表明，我们的损失函数的梯度鼓励从hard positive和hard negative中学习。我们还表明，三联体损失是我们损失只有一个正极和负极被使用的一个特例。</li>
</ol>
<p>具体来说，有监督对比学习的框架是交叉熵loss和传统对比学习的结合:</p>
<img src="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.2.png" alt="三种框架" style="zoom:80%;" />

<h2 id="2-具体结构"><a href="#2-具体结构" class="headerlink" title="2 具体结构"></a>2 具体结构</h2><h3 id="2-1-表征学习框架"><a href="#2-1-表征学习框架" class="headerlink" title="2.1 表征学习框架"></a>2.1 表征学习框架</h3><p>总的来说，有监督对比学习框架的结构类似于表征学习框架，由如下几个部分组成：</p>
<ol>
<li><p><strong>数据增强模块</strong></p>
<p>数据增强模块$A(·)$的作用是将输入图像转换为随机增强的图像$\widetilde{x}$，对每张图像都生成两张增强的子图像，代表原始数据的不同视图。数据增强分为两个阶段：第一阶段是对数据进行<strong>随机裁剪</strong>，然后将其调整为原分辨率大小；第二阶段使用了三种不同的增强方法，具体包括：（1）<strong>自动增强</strong>，（2）<strong>随机增强</strong>，（3）<strong>Sim增强</strong>（按照顺序进行随机颜色失真和高斯模糊，并可能在序列最后进行额外的稀疏图像扭曲操作）。</p>
</li>
<li><p><strong>编码器网络</strong></p>
<p>编码器网络$E(·)$的作用是将增强后的图像$\widetilde{x}$映射到表征空间，每对子图像输入到同一个编码器中得到一对表征向量，本文用的是ResNet50和ResNet200，最后使用池化层得到一个2048维的表征向量。表征层使用单位超球面进行正则化。</p>
</li>
<li><p><strong>投影网络</strong></p>
<p>投影网络$P(·)$的作用是将表征向量映射成一个最终向量$z$进行loss的计算，本文用的是只有一个隐藏层的多层感知器，输出维度为128。同样使用单位超球面进行正则化。在训练完成后，这个网络会被一个单一线性层取代。</p>
</li>
</ol>
<h3 id="2-2-对比损失"><a href="#2-2-对比损失" class="headerlink" title="2.2 对比损失"></a>2.2 对比损失</h3><p>本文的数据是带有标签的，采用mini batch的方法获取数据，首先从数据中随机采样$N$个样本对，记为$\left&lt;!–swig￼0–&gt;\<br>\mathcal{L}<em>{i}^{self}=-\log\frac{\exp(z_i·z_{j(i)}/\tau)}{\sum</em>{k=1}^{2N}{\mathbb{l}<em>{[k{\neq}i]}·\exp(z_i·z_{j(i)}/\tau)}}<br>$$<br>上式中，$\mathbb{l}</em>{[k{\neq}i]}$是一个指示函数，当且仅当$k=i$时取0，否则为1。$\tau$是进行优化的温度参数。该loss的意义在于拉近$\widetilde{x}<em>i$于其正对$\widetilde{x}</em>{j(i)}$之间的距离而拉远$\widetilde{x}_i$与其他负对之间的距离。</p>
<h4 id="2-2-2-有监督的对比损失"><a href="#2-2-2-有监督的对比损失" class="headerlink" title="2.2.2 有监督的对比损失"></a>2.2.2 有监督的对比损失</h4><p>有监督对比损失是对自监督对比损失的推广，从公式中很容易可以看出，有监督对比损失拓展了$\widetilde{x}<em>i$正对的数量，将所有标签信息相同的子数据都视为正对，计算了$\widetilde{x}<em>i$与其所有正对之间的相似性，之后进行加权平均。<br>$$<br>\mathcal{L}^{sup}=\sum</em>{i=1}^{2N}{\mathcal{L}</em>{i}^{sup}}\<br>\mathcal{L}<em>{i}^{sup}=\frac{-1}{2N</em>{\widetilde{y}<em>i}-1}\sum</em>{j=1}^{2N}{\mathbb{l}<em>{[i{\neq}j]}·\mathbb{l}</em>{[{\widetilde{y}<em>i}={\widetilde{y}_j}]}}·\log\frac{\exp(z_i·z</em>{j(i)}/\tau)}{\sum_{k=1}^{2N}{\mathbb{l}_{[k{\neq}i]}·\exp(z_i·z_{j(i)}/\tau)}}<br>$$<br>作者指出对比损失的核心是足够多的负对，以便与正对形成鲜明的对比，他们的改进监督对比损失保留了这一特性。此外，由于增加了正对的数量，这一架构还可以更好地刻画类内相似性。</p>
<h4 id="2-2-3-有监督对比损失的梯度特性"><a href="#2-2-3-有监督对比损失的梯度特性" class="headerlink" title="2.2.3 有监督对比损失的梯度特性"></a>2.2.3 有监督对比损失的梯度特性</h4><p>这一部分论证了hard positive和hard negative更有助于提升网络的性能，主要是通过对有监督对比损失的梯度进行分析，在此略去。</p>
<p>此外，作者在论文中还论述了三联loss是他们的有监督对比损失的特例，此处省略不讲。</p>
<h2 id="3-实验"><a href="#3-实验" class="headerlink" title="3 实验"></a>3 实验</h2><p>作者在评估其框架性能时，使用了<strong>Top-1精度</strong>和<strong>对损坏图像的鲁棒性</strong>两个方面进行衡量，还评价了其模型<strong>对超参数的稳定性</strong>以及<strong>正对数量</strong>对模型表现的影响。在实现上，使用的是训练好的网络，之后将网络的非线性投影头替换成一个简单的线性全连接层，使用标准交叉熵损失训练这个线性层。网络的训练在ImageNet上进行。</p>
<h3 id="3-1-ImageNet分类精度"><a href="#3-1-ImageNet分类精度" class="headerlink" title="3.1 ImageNet分类精度"></a>3.1 ImageNet分类精度</h3><p>这部分实验比较了他们的方法与其他使用交叉熵的有监督方法的Top-1与Top-5精度，同时对比了他们的架构使用交叉熵损失的表现，可以看到，综合来说他们的方法实现了最好的效果，同时，他们的架构在使用交叉熵损失时的表现就不是非常好，相对来说，他们的架构在改进loss的情况下，Top-1精度提升了3.8/2.8个点，Top-5精度提升了1/2.3个点。</p>
<img src="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.3.png" alt="线性分类评估" style="zoom:80%;" />

<h3 id="3-2-对图像损坏和校准的鲁棒性"><a href="#3-2-对图像损坏和校准的鲁棒性" class="headerlink" title="3.2 对图像损坏和校准的鲁棒性"></a>3.2 对图像损坏和校准的鲁棒性</h3><p>这部分实验评价了他们的方法对图像扰动的稳定性，具体来说，他们选择使用对ImageNet数据库中的图像应用常见的自然扰动，比如加噪声、模糊和对比度变化，构造得到的ImageNet-c数据集进行测试。使用平均损坏误差与平均相对损坏误差作为评价指标，可以看到，他们的方法的误差最小，且使用改进的对比损失替换交叉熵损失也有助于提升网络的性能。</p>
<img src="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.4.png" alt="平均损坏误差" style="zoom:80%;" />

<p>此外，和交叉熵损失相比，本文的对比损失在不同程度的图像损坏下都能保持一个相对稳定的平均损失误差，相比于交叉熵损失也有更高的Top-1精度：</p>
<img src="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.8.png" alt="与交叉熵损失的对比" style="zoom: 67%;" />

<h3 id="3-3-对超参数的鲁棒性"><a href="#3-3-对超参数的鲁棒性" class="headerlink" title="3.3 对超参数的鲁棒性"></a>3.3 对超参数的鲁棒性</h3><p>通常深度网络对超参数都很敏感，本文还比较了他们的改进对比损失对不同优化器、不同数据增强和学习率的分类精度稳定性。三种增强方式是本文提出的三种；优化器则选用了LARS、带动量的SGD和RMSProp；选择了最佳学习率以及增大或减小十倍的三个学习率进行评估，可以发现，本文提出的loss确实和交叉熵损失相比，对这三种超参数的变化更鲁棒。</p>
<img src="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.5.png" alt="对超参数的鲁棒性" style="zoom:67%;" />

<h3 id="3-4-不同正对数量对模型表现的影响"><a href="#3-4-不同正对数量对模型表现的影响" class="headerlink" title="3.4 不同正对数量对模型表现的影响"></a>3.4 不同正对数量对模型表现的影响</h3><p>作者对比了每个子数据有1、2、3、5个正对时的Top-1精度，发现正对越多越有助于提升模型表现，当然同时计算成本也更大。</p>
<img src="http://little_z_c.gitee.io/imagebed/Contrastive%20Learning%E7%9B%B8%E5%85%B3/%E3%80%8ASupervised%20Contrastive%20Learning%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/3.7.png" alt="不同正对数量的影响" style="zoom:80%;" />
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/12/26/%E3%80%8AContrastive%20Learning%20with%20Hard%20Negative%20Samples%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" rel="next" title="《Contrastive Learning with Hard Negative Samples》阅读笔记">
                <i class="fa fa-chevron-left"></i> 《Contrastive Learning with Hard Negative Samples》阅读笔记
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%20%7C%7C%20archive">
              
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E6%A6%82%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text">1 概要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%85%B7%E4%BD%93%E7%BB%93%E6%9E%84"><span class="nav-number">2.</span> <span class="nav-text">2 具体结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 表征学习框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-%E5%AF%B9%E6%AF%94%E6%8D%9F%E5%A4%B1"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 对比损失</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-%E6%9C%89%E7%9B%91%E7%9D%A3%E7%9A%84%E5%AF%B9%E6%AF%94%E6%8D%9F%E5%A4%B1"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.2.2 有监督的对比损失</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-3-%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E6%8D%9F%E5%A4%B1%E7%9A%84%E6%A2%AF%E5%BA%A6%E7%89%B9%E6%80%A7"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.2.3 有监督对比损失的梯度特性</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E5%AE%9E%E9%AA%8C"><span class="nav-number">3.</span> <span class="nav-text">3 实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-ImageNet%E5%88%86%E7%B1%BB%E7%B2%BE%E5%BA%A6"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 ImageNet分类精度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-%E5%AF%B9%E5%9B%BE%E5%83%8F%E6%8D%9F%E5%9D%8F%E5%92%8C%E6%A0%A1%E5%87%86%E7%9A%84%E9%B2%81%E6%A3%92%E6%80%A7"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 对图像损坏和校准的鲁棒性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-%E5%AF%B9%E8%B6%85%E5%8F%82%E6%95%B0%E7%9A%84%E9%B2%81%E6%A3%92%E6%80%A7"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 对超参数的鲁棒性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-%E4%B8%8D%E5%90%8C%E6%AD%A3%E5%AF%B9%E6%95%B0%E9%87%8F%E5%AF%B9%E6%A8%A1%E5%9E%8B%E8%A1%A8%E7%8E%B0%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="nav-number">3.4.</span> <span class="nav-text">3.4 不同正对数量对模型表现的影响</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">微澜</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
